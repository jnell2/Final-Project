Day 1:
10/31/2016
Overwhelmed with data, so I did research to try to find similar projects that have already been done.
No Githubs, but a few papers. Used very basic measure and ran models achieving a maximum accuracy around 60%.
Struggled through web scraping, found out I had to use selenium.
Finally got my first data table loaded into a pandas dataframe.

Day 2:
11/01/2016
Adjusted web-scraping code to get other data tables I needed.
All are loaded into pandas dataframes.
Trying to scrape nhl standings, but running into 2 issues:
1) website is same for all tabs, need to figure out how to have scraping code actually look at the "league" tab
2) the first column of the table has 3 elements, need to figure out how to get all 3 elements.

Day 3:
11/02/2016
Up until 1:00, was struggling with the nhl standings webpage trying to scrape the nhl standings.
Tried several different approaches, kept funning into issues.
Started looking at other sources where I could get the nhl standings.
Figured out that if I sort a table that I have already scraped in a certain way, I can get the standings.
(Table: Season Team Summary, Sort: points, wins, games played)

From here, I will compile the final dataset that I will work with. I have 7 tables that I scraped.
3 are game-by-game stats and 4 are season stats.
I want my final data table to be cumulative stats for each team for the past 10 games.
(or seasonal stats, like standings, missed shots [corsi, fenwick], etc.)
There will be 30 rows (30 teams).
For now, I think I will do this using pandas dataframes, just to save time since I wasted so much trying to get the standings.
I will end up having 2 final pandas dataframes:
1) the total table with all games, game-by-game, from the specified time period (only GbG data)
2) the table with each team having a single row, add in season data, calculate fields
First steps will be to merge my GbG pandas dataframes to keep all of the columns that I want.
This will be df 1.
Next steps will be to combine rows in pandas dataframe for past 10 games.
Then I will add the SbS dataframe information that I want to keep.
Then I will add calculated columns.
This will be df 2.

Day 4:
11/03/2016
Just realized last night that I need a different final data table.
In order to predict wins, I need to keep information in a game-by-game format.
So I will need 3 separate dataframes to get here.
1) the total table with all games, game-by-game, from the specified time period (only GbG data)
2) the table with each team having a single row (past 10 games) , add in season data, calculate fields
3) the table with home/away teams and an indicator for whether or not the home team won.
This will come from the GbG data. Then for each game, I will supplement the information from table 2.

Issues: had to fix non-ascii characters. Only getting first page of data for GbG data.
Need to do: get the rest of the pages, clean pandas dfs, save as csvs, use postgres to get final data tables.

Day 5:
11/04/2016
To do today: get the rest of the pages for the data tables, clean pandas dfs,
save as csvs, use postgres to get final data tables.
Maybe do some work this weekend to get further ahead--I've run into a lot of issues.

Finally got WebScraping.py working correctly!

Suggestion from Adam: maybe predict the goal spread instead of W/L
Simple web app with home/away team, logo, and button to predict
Good idea to look at length of time.

Need to do this weekend:
1) clean up pandas dataframes
2) save dataframes as csv
3) combine tables to get the tables that I want. want to have different time periods.
4) if time, start running some models.

Day 6:
11/06/2016
all dataframes are being collected nicely
automated some of the process. no longer need to change page numbers or any dates.
next steps are to clean up the dataframes, make new tables, and save these as csvs.
dataframes are clean. next step: make necessary tables.

Day 7:
11/07/2016
dataframes are cleaned. now need to get final 4 datatables that I need.
tables will be game by game with cumulative stats for either past 10 games,
past 5 games, past 2 games, or current season.
maybe make 3 extra tables with cumulative stats for either past 10 games, past
5 games, and past 2 games with certain season statistics mixed in.
Total of 7 tables.
as of 11:30, i have 3 of my final tables: the game by game tables with cumulative
stats for past 10, 5, 2 games

Day 8:
11/08/2016
finished cleaning up data. finally got a data table that i can work with.
wrote code for logistic regression. got an accuracy score of 60%.
this was using data from past 15 games, predicting W/L of home team.

Day 9:
11/09/2016
wrote code for more models: linear regression, RF classifier, RF Regressor
wrote code to determine RMSE for a common way to compare models.
all linear regressions have high RMSE score and negative R2 values?
RF classifier with data for 15 games produces exact same accuracy score (60%) as
logistic regression on same data, with exact same RMSE
XGboost with data for 10 games give accuracy 62.2%, rmse of 0.61.
this is the best model so far.
maybe try SVM and NN?
maybe want to make a new data set with 5/10/15 data and use ratio predictors
instead of separate H/A predictors.
tomorrow, i want to pick a model and fine tune it.
start making draft of presentation for friday.

Day 10:
11/10/2016
To Do Today:
- maybe do NN
- optimize model
- make visualizations
- make presentation outline
- how to predict real time data? input home team, away team, date, return prediction

Presentation outline
- title page
- project intro
- web scraping, data cleaning
- models tried
- visualization comparing models
- optimal model
- predictions
- maybe web app?

5 best models:
1) XGboost classifier, 10 games (accuracy = 62.2%)
2) MLP, 10 games proportional (accuracy = 62.2%)
3) MLP, 15 games proportional (accuracy = 62.2%)
4) RF classifier, 15 games (accuracy = 60.0%)
5) logistic, 15 games (accuracy = 60.0%)

will do grid search on 5 above models.
** need to see what accuracy does with and without predictors

best model: RFR, 10 games
without:
- shots, save%, shot% = 66% accuracy
- shots, shot% = 66% accuracy
- shots, save%, PDO = 66% accuracy
- shots, shot%, PDO = 66% accuracy

Day 11:
11/11/2016
having trouble with choosing a model. accuracy changes drastically every time
I update my data.
To do: replace train_test_split with KFold, pull data for last season,
create a moving df based on most recent 10 games?

pulled data for last season.
performed kfold cross validation on data from last season.
best model: mlp, 5 games. accuracy = 55.6%

Day 12:
11/12/2016
played with models and interaction terms using last seasons data.
best model is still mlp, 5 games (without giveaways). accuracy = 55.6%
pulled most recent data from nhl.com, data gets accuracy of 53% when run through kfold model.
got 51% last night.
next steps:
1) pickle model (so don't have to retrain)
2) write function that takes in new data
3) write function that makes predictions

MAKING PREDICTIONS!!!!

Day 13:
11/13/2016
optimizing mlp classifier and regressor. new best model is mlp regressor.
when training on last seasons data, accuracy is 57.23%.
mlp classifier is 57.19%.
today, will work on visualizations and putting together presentation. 
